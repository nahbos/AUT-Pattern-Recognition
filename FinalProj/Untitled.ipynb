{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7984d1c0",
   "metadata": {},
   "source": [
    "#### Copyright (C) 2022 Sobhan Moradian Daghigh\n",
    "#### Date: 2/2/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6316f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b603ab59",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b878f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38554a",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750d2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(path):\n",
    "    datasets = []\n",
    "    print('Loading the datasets..\\n')\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for i, file in enumerate(files):\n",
    "            print(' |_  {}. {} loaded'.format(i + 1, file.split('.')[0]))\n",
    "            datasets.append(pd.read_csv(os.path.join(root, file), names=['sentence', 'label'], sep='\\t'))\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cae22699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the datasets..\n",
      "\n",
      " |_  1. amazon loaded\n",
      " |_  2. imdb loaded\n",
      " |_  3. yelp loaded\n"
     ]
    }
   ],
   "source": [
    "datasets_name = ['Amazon', 'IMDB', 'Yelp']\n",
    "datasets = load_datasets('./Datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa12b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5faf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  1000 non-null   object\n",
      " 1   label     1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Amazon\n",
    "datasets[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d6203cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  748 non-null    object\n",
      " 1   label     748 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# IMDB\n",
    "datasets[1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a79970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  1000 non-null   object\n",
      " 1   label     1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Yelp\n",
    "datasets[2].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02359353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f36efac",
   "metadata": {},
   "source": [
    "### Train - Test - Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9210ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliter(datasets):\n",
    "    x_train_datasets, x_test_datasets, y_train_datasets, y_test_datasets = [], [], [], []\n",
    "    for dataset in datasets:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(dataset.sentence, dataset.label, test_size=0.3, random_state=0)\n",
    "        x_train_datasets.append(x_train)\n",
    "        x_test_datasets.append(x_test)\n",
    "        y_train_datasets.append(y_train)\n",
    "        y_test_datasets.append(y_test)\n",
    "    return x_train_datasets, x_test_datasets, y_train_datasets, y_test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d213e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_datasets, x_test_datasets, y_train_datasets, y_test_datasets = spliter(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49712a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f97608e",
   "metadata": {},
   "source": [
    "### Feature extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "933f2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(dataset):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(dataset)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9dd8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_frequent_features(vectorizer):\n",
    "    df = pd.DataFrame({'words': vectorizer.vocabulary_.keys(), 'counts': vectorizer.vocabulary_.values()})\n",
    "    print('{}:'.format(datasets_name[i]))\n",
    "    display(df.sort_values(by=['counts'], ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2562850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "170b6428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output {flex-direction: row;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Render DataFrames side by side by CSS override\n",
    "css = \"\"\".output {flex-direction: row;}\"\"\"\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6a150",
   "metadata": {},
   "source": [
    "### Top 5 frequent words of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d83d3f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>zero</td>\n",
       "      <td>1494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>your</td>\n",
       "      <td>1493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>you</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>yet</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>yes</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words  counts\n",
       "665   zero    1494\n",
       "121   your    1493\n",
       "117    you    1492\n",
       "703    yet    1491\n",
       "1475   yes    1490"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>zombiez</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>zombie</td>\n",
       "      <td>2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>zillion</td>\n",
       "      <td>2437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>youtube</td>\n",
       "      <td>2436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>youthful</td>\n",
       "      <td>2435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         words  counts\n",
       "1931   zombiez    2439\n",
       "1107    zombie    2438\n",
       "1447   zillion    2437\n",
       "152    youtube    2436\n",
       "2099  youthful    2435"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>zero</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>yummy</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>yukon</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>yucky</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>yourself</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         words  counts\n",
       "264       zero    1648\n",
       "629      yummy    1647\n",
       "1429     yukon    1646\n",
       "989      yucky    1645\n",
       "366   yourself    1644"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display\n",
    "vectorizers = []\n",
    "for i, dataset in enumerate(x_train_datasets):\n",
    "    vectorizer = feature_extractor(dataset)\n",
    "    get_top_frequent_features(vectorizer)\n",
    "    vectorizers.append(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118de58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4af4610",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "58ad6513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      " |_  Amazon: 0.753\n",
      " |_  IMDB: 0.684\n",
      " |_  Yelp: 0.793\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\")\n",
    "for i, (vec, x_tr, x_ts, y_tr, y_ts) in enumerate(zip(vectorizers, x_train_datasets, x_test_datasets, y_train_datasets, y_test_datasets)):\n",
    "    X_train = vectorizer.transform(x_tr)\n",
    "    X_test = vectorizer.transform(x_ts)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_tr)\n",
    "    score = clf.score(X_test, y_ts)\n",
    "    \n",
    "    print(' |_  {}: {:.3f}'.format(datasets_name[i], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba76308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfde6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e422e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae453f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9a050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db60eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93283bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca3059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eec3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445627c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796b9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1b6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ba4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12eec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3d2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426f27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f107ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff9392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d6c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
