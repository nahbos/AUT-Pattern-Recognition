{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Rand.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nahbos/AUT-Pattern-Recognition/blob/main/FinalProj/CNN_Rand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Copyright (C) 2022 Sobhan Moradian Daghigh**\n",
        "######**Date: 2/10/2022**"
      ],
      "metadata": {
        "id": "7GlPaFweH1fa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H7Ynha2lHj7"
      },
      "source": [
        "###**Preparing the pre-trained GloVe model**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading pre-trained GloVe**"
      ],
      "metadata": {
        "id": "_4SNsCZBrXwE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlC4m7alB44c"
      },
      "source": [
        "import requests, zipfile, io\n",
        "zip_file_url = \"http://nlp.stanford.edu/data/glove.840B.300d.zip\"\n",
        "r = requests.get(zip_file_url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nwtJSh9qeLt7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "LDoEypbsd9OD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEh0D8DSH1L4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9edfd6-56b5-45ef-bfe4-9d43a0066342"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import BatchNormalization\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from tqdm import tqdm\n",
        "import codecs\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "MAX_NB_WORDS = 100000"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P8dmJYV9eO4i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OryI3DKE8tr8"
      },
      "source": [
        "**Converting all the words to the embedding index in pre-trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPqS-8FcEN95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe51e7a-9bdf-43a3-9a2f-0575ff08a37d"
      },
      "source": [
        "print('Loading word embeddings..')\n",
        "\n",
        "embeddings_index = {}\n",
        "f = codecs.open('./glove.840B.300d.txt', encoding='utf-8')\n",
        "\n",
        "for line in tqdm(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading word embeddings..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2196018it [04:23, 8342.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X2OknGbSeQ3i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a preprocess on the comments to improve quality and remove unneccessary words**\n",
        "1. convert all words to lowercase\n",
        "2. remove punctuations\n",
        "3. tonekize words\n",
        "4. remove stopwords\n",
        "5. use porterStemmer to have stemming words"
      ],
      "metadata": {
        "id": "n7HpKZXMe8_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nlprocess(dataset):\n",
        "\n",
        "  preprocessed_comments = []\n",
        "  for _, text in dataset.iterrows():\n",
        "\n",
        "      text = text[0]\n",
        "      #Lowercase\n",
        "      text = text.lower()\n",
        "\n",
        "      # Removing Punctuation\n",
        "      text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "      # Word Tokenization\n",
        "      text = word_tokenize(text)\n",
        "\n",
        "      # Stopword Filtering\n",
        "      stop_words = stopwords.words('english')\n",
        "      text = [word for word in text if word not in stop_words]\n",
        "\n",
        "      # Stemming\n",
        "      porter = PorterStemmer()\n",
        "      text = [porter.stem(word) for word in text]\n",
        "\n",
        "      text = ' '.join(text)\n",
        "\n",
        "      preprocessed_comments.append(text)\n",
        "      \n",
        "  return preprocessed_comments"
      ],
      "metadata": {
        "id": "gfJ2dbsJ_nMP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spliter(datasets):\n",
        "    x_train_datasets, x_test_datasets, y_train_datasets, y_test_datasets = [], [], [], []\n",
        "    print('(train, test):')\n",
        "    for i, dataset in enumerate(datasets):\n",
        "        x_train, x_test = dataset[0], dataset[1]\n",
        "        tr, ts = np.zeros(len(x_train)), np.zeros(len(x_test))\n",
        "        tr[:len(x_train) // 2], ts[:len(x_test) // 2] = 1, 1\n",
        "        y_train, y_test = tr, ts\n",
        "\n",
        "        x_train_datasets.append(nlprocess(x_train))\n",
        "        x_test_datasets.append(nlprocess(x_test))\n",
        "        y_train_datasets.append(y_train)\n",
        "        y_test_datasets.append(y_test)\n",
        "        print(' |_ {}: ({}, {})'.format(datasets_name[i], len(x_train), len(x_test)))\n",
        "    return x_train_datasets, x_test_datasets, y_train_datasets, y_test_datasets"
      ],
      "metadata": {
        "id": "QetfY78V_7kW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXof0wFo6Q8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368e031b-e7af-4d18-d9b3-c771b6fef44f"
      },
      "source": [
        "datasets_name = ['Books      ', 'DVD        ', 'Electronics', 'Kitchen    ']\n",
        "\n",
        "# Load data\n",
        "datasets = []\n",
        "\n",
        "books_train = pd.read_csv('./Bookstrain.txt', names=['text'], sep='\\t')\n",
        "books_test = pd.read_csv('./Bookstest.txt', names=['text'], sep='\\t')\n",
        "datasets.append([books_train, books_test])\n",
        "\n",
        "dvd_train = pd.read_csv('./Dvdtrain.txt', names=['text'], sep='\\t')\n",
        "dvd_test = pd.read_csv('./Dvdtest.txt', names=['text'], sep='\\t')\n",
        "datasets.append([dvd_train, dvd_test])\n",
        "\n",
        "electronics_train = pd.read_csv('./Electronicstrain.txt', names=['text'], sep='\\t')\n",
        "electronics_test = pd.read_csv('./Electronicstest.txt', names=['text'], sep='\\t')\n",
        "datasets.append([electronics_train, electronics_test])\n",
        "\n",
        "kitchen_train = pd.read_csv('./Kitchentrain.txt', names=['text'], sep='\\t')\n",
        "kitchen_test = pd.read_csv('./Kitchentest.txt', names=['text'], sep='\\t')\n",
        "datasets.append([kitchen_train, kitchen_test])\n",
        "\n",
        "\n",
        "x_train_datasets, x_test_datasets, y_train_datasets, y_test_datasets = spliter(datasets)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(train, test):\n",
            " |_ Books      : (1600, 400)\n",
            " |_ DVD        : (1600, 400)\n",
            " |_ Electronics: (1600, 400)\n",
            " |_ Kitchen    : (1600, 400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cxTLPm3seTLy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_AOE1b5elSz"
      },
      "source": [
        "**Tokenizing the data with tokenizer from tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc_9P1cEGg5J"
      },
      "source": [
        "def tokenizer(x_train_datasets, x_test_datasets):\n",
        "  word_indices = []\n",
        "  word_seq_trains = []\n",
        "  word_seq_tests = []\n",
        "  max_seq_lens = []\n",
        "\n",
        "  print(\"Dictionary size:\")\n",
        "  for i, (x_tr, x_ts) in enumerate(zip(x_train_datasets, x_test_datasets)):\n",
        "    (x_tr, x_ts) = (pd.DataFrame(x_tr, columns=['text']), pd.DataFrame(x_ts, columns=['text']))\n",
        "    raw_docs_train = x_tr.text.tolist()\n",
        "    raw_docs_test  = x_ts.text.tolist()\n",
        "\n",
        "\n",
        "    processed_docs_train = []\n",
        "    for doc in tqdm(raw_docs_train):\n",
        "        tokens = word_tokenize(doc)\n",
        "        processed_docs_train.append(\" \".join(tokens))\n",
        "\n",
        "    processed_docs_test = []\n",
        "    for doc in tqdm(raw_docs_test):\n",
        "        tokens = word_tokenize(doc)\n",
        "        processed_docs_test.append(\" \".join(tokens))\n",
        "\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, char_level=False)\n",
        "    tokenizer.fit_on_texts(processed_docs_train + processed_docs_test)\n",
        "    word_seq_train = tokenizer.texts_to_sequences(processed_docs_train)\n",
        "    word_seq_test  = tokenizer.texts_to_sequences(processed_docs_test)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    word_indices.append(word_index)\n",
        "    print(\" |_ {}: {}\".format(datasets_name[i], len(word_index)))\n",
        "\n",
        "    x_tr['doc_len'] = x_tr.text.apply(lambda words: len(words.split(' ')))\n",
        "    max_seq_len = np.round(x_tr.doc_len.mean() + x_tr.doc_len.std()).astype(int)\n",
        "    max_seq_lens.append(max_seq_len)\n",
        "    x_tr = x_tr.drop('doc_len', axis=1)\n",
        "    word_seq_trains.append(sequence.pad_sequences(word_seq_train, maxlen=max_seq_len))\n",
        "    word_seq_tests.append(sequence.pad_sequences(word_seq_test, maxlen=max_seq_len))\n",
        "\n",
        "  return word_indices, word_seq_trains, word_seq_tests, max_seq_lens"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_indices, word_seq_trains, word_seq_tests, max_seq_lens = tokenizer(x_train_datasets, x_test_datasets)"
      ],
      "metadata": {
        "id": "kJsBfc6eBPCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "190a71de-8af5-4bbf-8c2b-450575dea09d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary size:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [00:00<00:00, 1687.11it/s]\n",
            "100%|██████████| 400/400 [00:00<00:00, 1768.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " |_ Books      : 20293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [00:00<00:00, 1722.84it/s]\n",
            "100%|██████████| 400/400 [00:00<00:00, 1831.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " |_ DVD        : 21192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [00:00<00:00, 2832.74it/s]\n",
            "100%|██████████| 400/400 [00:00<00:00, 2683.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " |_ Electronics: 11679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [00:00<00:00, 3389.07it/s]\n",
            "100%|██████████| 400/400 [00:00<00:00, 3397.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " |_ Kitchen    : 9011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_6k8V1MteYP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpGENGlOtQs1"
      },
      "source": [
        "###**Shape and Train with CNN-Static**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyj7gwQKexxy"
      },
      "source": [
        "**defining variables that used on training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSZ3krGMG303"
      },
      "source": [
        "# Training params\n",
        "batch_size = 256 \n",
        "num_epochs = 20\n",
        "\n",
        "# Model params\n",
        "num_filters = 64 \n",
        "embed_dim = 300 \n",
        "weight_decay = 1e-4"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ6AlbhZe4Ky"
      },
      "source": [
        "**All words that arent in the pre-trained model from GloVe would be changed to 0. These words are basically the ones with names, and mostly dont matter so much to the pattern. so its nicer to just weights it 0.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SJbfuJPJEDC"
      },
      "source": [
        "# Embedding matrix\n",
        "def embd_matrix(word_indices):\n",
        "  nb_words_list = []\n",
        "  embedding_matrices = []\n",
        "  print('Preparing embedding matrix..')\n",
        "  print(' Number of null word embeddings:')\n",
        "  for j, word_index in enumerate(word_indices):\n",
        "    words_not_found = []\n",
        "    nb_words = min(MAX_NB_WORDS, len(word_index) + 1)\n",
        "    nb_words_list.append(nb_words)\n",
        "    embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "\n",
        "    for word, i in word_index.items():\n",
        "        if i >= nb_words:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            words_not_found.append(word)\n",
        "    \n",
        "    embedding_matrices.append(embedding_matrix)\n",
        "    print('  |_ {}: {}'.format(datasets_name[j], np.sum(np.sum(embedding_matrix, axis=1) == 0)))\n",
        "    print(\"     some of not-found words: {}\".format(np.random.choice(words_not_found, 3)))\n",
        "  \n",
        "  return nb_words_list, embedding_matrices"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_pjm-7BJGuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce658823-c8de-4018-f4fc-0e9d6ca667c2"
      },
      "source": [
        "nb_words_list, embedding_matrices = embd_matrix(word_indices)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing embedding matrix..\n",
            " Number of null word embeddings:\n",
            "  |_ Books      : 8904\n",
            "     some of not-found words: ['ellroy' 'facad' 'lovemap']\n",
            "  |_ DVD        : 9368\n",
            "     some of not-found words: ['insteadaft' 'doofusesand' 'gravelli']\n",
            "  |_ Electronics: 5029\n",
            "     some of not-found words: ['nonintuit' 'soundgrant' 'lowerneed']\n",
            "  |_ Kitchen    : 3420\n",
            "     some of not-found words: ['quicklyy' 'mistur' 'misquot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cool :)))**"
      ],
      "metadata": {
        "id": "YPQCCaKj13lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "72T_QAwuebgE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUBAkn22ga48"
      },
      "source": [
        "**Now, lets start training!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpX2AFhKJJsh"
      },
      "source": [
        "def glove_trainer(word_indices, nb_words_list, max_seq_lens, y_train_datasets, word_seq_trains):\n",
        "  models = []\n",
        "  for i, (word_index, nb_words, max_seq_len, y_train, word_seq_train) in enumerate(zip(word_indices, nb_words_list, max_seq_lens, y_train_datasets, word_seq_trains)):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    embedding_matrix2 = np.random.uniform(-1, 1, (len(word_index)  + 1, embed_dim))\n",
        "    \n",
        "    model.add(Embedding(nb_words, embed_dim, input_length=max_seq_len, weights=[embedding_matrix2], trainable=False))\n",
        "    model.add(Conv1D(128, 5, activation='relu'))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    print('\\n\\n****************************   {}   ************************'.format(datasets_name[i]))\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    es_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "    model.fit(word_seq_train, y_train, batch_size=256, epochs=num_epochs, callbacks=[es_callback], shuffle=False)\n",
        "\n",
        "    models.append(model)\n",
        "    keras.backend.clear_session()\n",
        "  return models"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NAQDunZFsHiP"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = glove_trainer(word_indices, nb_words_list, max_seq_lens, y_train_datasets, word_seq_trains)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9oADMCL4lmj",
        "outputId": "881c7f86-0bd2-4cae-e5b6-e624b6e0a7a9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "****************************   Books         ************************\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 323, 300)          6088200   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 319, 128)          192128    \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,281,629\n",
            "Trainable params: 193,429\n",
            "Non-trainable params: 6,088,200\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.6430 - accuracy: 0.4681WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6430 - accuracy: 0.4681\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5156 - accuracy: 0.7644WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5156 - accuracy: 0.7644\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6269 - accuracy: 0.5600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6269 - accuracy: 0.5600\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.5300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6391 - accuracy: 0.5300\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.7644WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5412 - accuracy: 0.7644\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4616 - accuracy: 0.9331WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4616 - accuracy: 0.9331\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3701 - accuracy: 0.9912WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.3701 - accuracy: 0.9912\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.9937WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.3293 - accuracy: 0.9937\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.9956WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3070 - accuracy: 0.9956\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.2709 - accuracy: 0.9987\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.2373 - accuracy: 0.9994\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.2159 - accuracy: 0.9994\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1879 - accuracy: 0.9994\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1774 - accuracy: 0.9994\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.1438 - accuracy: 0.9994\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1306 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1034 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0930 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0787 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0701 - accuracy: 1.0000\n",
            "\n",
            "\n",
            "****************************   DVD           ************************\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 316, 300)          6357900   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 312, 128)          192128    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,551,329\n",
            "Trainable params: 193,429\n",
            "Non-trainable params: 6,357,900\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2867 - accuracy: 0.2469WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2867 - accuracy: 0.2469\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4556WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6935 - accuracy: 0.4556\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6887 - accuracy: 0.6325WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6887 - accuracy: 0.6325\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.6012WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6863 - accuracy: 0.6012\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6825 - accuracy: 0.6112WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6825 - accuracy: 0.6112\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.6031WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6791 - accuracy: 0.6031\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6747 - accuracy: 0.6406WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6747 - accuracy: 0.6406\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.6419WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6588 - accuracy: 0.6419\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.6463WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6625 - accuracy: 0.6463\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.7387WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6381 - accuracy: 0.7387\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6214 - accuracy: 0.7369WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6214 - accuracy: 0.7369\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.6850WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6738 - accuracy: 0.6850\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.8981WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6208 - accuracy: 0.8981\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.9050WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6055 - accuracy: 0.9050\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.9212WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5884 - accuracy: 0.9212\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.9488WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5596 - accuracy: 0.9488\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.9556WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5190 - accuracy: 0.9556\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.8950WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4879 - accuracy: 0.8950\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.8894WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4638 - accuracy: 0.8894\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.9694WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3286 - accuracy: 0.9694\n",
            "\n",
            "\n",
            "****************************   Electronics   ************************\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 177, 300)          3504000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 173, 128)          192128    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,697,429\n",
            "Trainable params: 193,429\n",
            "Non-trainable params: 3,504,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3478 - accuracy: 0.4062WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 5s 578ms/step - loss: 1.3478 - accuracy: 0.4062\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.9050WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 575ms/step - loss: 0.5115 - accuracy: 0.9050\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.5425WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 572ms/step - loss: 0.6118 - accuracy: 0.5425\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.6325WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 580ms/step - loss: 0.5706 - accuracy: 0.6325\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.9244WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 577ms/step - loss: 0.4806 - accuracy: 0.9244\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.9787WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 577ms/step - loss: 0.4111 - accuracy: 0.9787\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.9856WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 576ms/step - loss: 0.3616 - accuracy: 0.9856\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3315 - accuracy: 0.9919WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 573ms/step - loss: 0.3315 - accuracy: 0.9919\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.9931WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 577ms/step - loss: 0.3059 - accuracy: 0.9931\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.9981WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 578ms/step - loss: 0.2773 - accuracy: 0.9981\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.9981WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 575ms/step - loss: 0.2495 - accuracy: 0.9981\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 582ms/step - loss: 0.2260 - accuracy: 0.9987\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2061 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 579ms/step - loss: 0.2061 - accuracy: 0.9987\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 584ms/step - loss: 0.1874 - accuracy: 0.9994\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 573ms/step - loss: 0.1701 - accuracy: 0.9994\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 575ms/step - loss: 0.1536 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 575ms/step - loss: 0.1387 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 575ms/step - loss: 0.1240 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 579ms/step - loss: 0.1099 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 574ms/step - loss: 0.0971 - accuracy: 1.0000\n",
            "\n",
            "\n",
            "****************************   Kitchen       ************************\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 140, 300)          2703600   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 136, 128)          192128    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,897,029\n",
            "Trainable params: 193,429\n",
            "Non-trainable params: 2,703,600\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 2.1934 - accuracy: 0.4550WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 4s 461ms/step - loss: 2.1934 - accuracy: 0.4550\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.9206WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 462ms/step - loss: 0.3584 - accuracy: 0.9206\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7106 - accuracy: 0.5306WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 459ms/step - loss: 0.7106 - accuracy: 0.5306\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.8438WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 458ms/step - loss: 0.4565 - accuracy: 0.8438\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.9463WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 464ms/step - loss: 0.3092 - accuracy: 0.9463\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9956WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 470ms/step - loss: 0.2072 - accuracy: 0.9956\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.9944WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 469ms/step - loss: 0.1931 - accuracy: 0.9944\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 461ms/step - loss: 0.1699 - accuracy: 0.9987\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 460ms/step - loss: 0.1351 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 464ms/step - loss: 0.1090 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 467ms/step - loss: 0.0947 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 461ms/step - loss: 0.0828 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 463ms/step - loss: 0.0719 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 462ms/step - loss: 0.0622 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 466ms/step - loss: 0.0548 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 461ms/step - loss: 0.0488 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 463ms/step - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 459ms/step - loss: 0.0389 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 465ms/step - loss: 0.0344 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 1.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "7/7 [==============================] - 3s 461ms/step - loss: 0.0312 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pzztI1rTefvr"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r0E47btUHg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2b41ff-1b1d-4300-dc6a-aa277e6f033c"
      },
      "source": [
        "print(\"Accuracy with GloVe and CNN-Rand:\")\n",
        "for i, (model, y_ts, word_seq_test) in enumerate(zip(models, y_test_datasets, word_seq_tests)):\n",
        "    predictions = (model.predict(word_seq_test) > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_ts, predictions)\n",
        "    print(' |_  {}: {:.2f}'.format(datasets_name[i], acc))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with GloVe and CNN-Rand:\n",
            " |_  Books      : 0.65\n",
            " |_  DVD        : 0.56\n",
            " |_  Electronics: 0.78\n",
            " |_  Kitchen    : 0.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finito :)**"
      ],
      "metadata": {
        "id": "5GLkQMQlcfWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n5QZBz-Dum58"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}